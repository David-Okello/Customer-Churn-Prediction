# Customer Churn Prediction Toolkit

> An end-to-end pipeline to simulate customer data, engineer features, and train a  Random Forest model for predicting customer churn.


## 🚀 Key Features

- **Synthetic Data Generation**  
  - `generate_customer_data.py` creates a realistic dataset of ~1,000 customers, including Recency-Frequency-Monetary (RFM) metrics, demographics, and support ticket counts.

- **Feature Engineering & Preprocessing**  
  - Automatic handling of missing values, scaling of numeric features, and encoding of categorical variables via Scikit-learn’s `ColumnTransformer`.

- **Model Training & Tuning**  
  - `churnpred.py` implements a `Pipeline` that engineers features and fits a `RandomForestClassifier` with hyperparameter tuning via `GridSearchCV`.

- **Evaluation & Persistence**  
  - Outputs best ROC AUC score and optimal hyperparameters.  
  - Saves the final `RandomForest` model as `churn_model.pkl` for downstream inference.

- **Reproducibility**  
  - All randomness is controlled via fixed random seeds.  
  - Dependencies locked in `requirements.txt`.



## 📂 Repository Structure
├── customer_data.csv # Synthetic dataset (auto-regenerated by the script)

├── generate_customer_data.py # Script to simulate and save customer data

├── churnpred.py # Full pipeline: preprocess, feature engineer, train, evaluate

├── churn_model.pkl # Serialized best Random Forest model

├── requirements.txt # Project dependencies

└── README.md # ← This file



## 🛠️ Installation

1. **Clone the repository**  
   ```bash
   git clone https://github.com/David-Okello/Customer-Churn-Prediction.git
   cd customer-churn-prediction
    ```
2. Create & activate a virtual environment
    ```bash
    python -m venv .venv
    # Windows
    .\.venv\Scripts\Activate
    # macOS/Linux
    source .venv/bin/activate
    ```
3. Install dependencies
    ```bash
    pip install --upgrade pip
    pip install -r requirements.txt
    ```
## 💡 Usage

1. Generate Synthetic Customer Data
    ```bash
    python generate_customer_data.py
    ```

    Produces customer_data.csv with features:

    - recency_days: Days since last purchase
    - frequency: Number of transactions
    - monetary_value: Total spend
    - region: Customer region (e.g., North America, EMEA)
    - tier: Service tier (e.g., Basic, Premium)
    - support_tickets: Number of tickets raised
    - churn: Binary target (0 = retained, 1 = churned)

2. Train & Evaluate the Churn Model
    ```bash
    python churnpred.py
    ```

    This triggers the full pipeline:

    1. Loads customer_data.csv.
    2. Preprocesses numeric & categorical features.
    3. Trains a RandomForestClassifier with hyperparameter tuning.
    4. Evaluates on a hold-out split.
    5. Prints metrics & parameters.
    6. Saves the final model to churn_model.pkl.

## 📊 Interpreting the Script Output (Nerding Out!😅)
When you run:
```cmd
(.venv) C:\…\customer-churn-prediction> python churnpred.py
Best ROC AUC: 1.0
Best params: {'clf__max_depth': 5, 'clf__n_estimators': 100}
Sample risk scores: [0.07642917 0.08650294 0.05018108]
```

Here’s what each line means:

1. Best ROC AUC: 1.0

    - ROC AUC (Receiver Operating Characteristic Area Under the Curve) is a measure of classification quality that ranges from 0.5 (no better than flipping a coin) to 1.0 (perfect).
    - A value of 1.0 means it perfectly separated churners from non-churners on the test split (common with clean, synthetic data).
        - In real-world scenarios you rarely see a perfect 1.0, but here it just shows “the pipeline worked and found a parameter set that perfectly classified the held-out examples.”

2. Best params: {'clf__max_depth': 5, 'clf__n_estimators': 100}
    
    These are the hyperparameters the grid search settled on:

    - n_estimators=100: The “forest” size i.e. how many decision trees the Random Forest builds. More trees can improve stability but cost more compute.
    - max_depth=5: 	How deep each tree is allowed to grow. A depth of 5 means each tree makes at most 5 “yes/no” splits from root to leaf. Each tree can split at most 5 times, controlling complexity.

3. Sample risk scores: [0.0764, 0.0865, 0.0502]

    These are predicted probabilities of churn for the first three customers in the test set. Think of each as:

    > “My model believes Customer #1 has a 7.64% chance of churning, Customer #2 about 8.65%, Customer #3 about 5.02%.”
    - e.g. 0.0764 → 7.64% chance of churning.

    Low numbers mean “likely to stay,” higher numbers (close to 1.0) would mean “very likely to churn. (not stay)” One can use these risk scores to prioritize who to call, send retention offers to, etc.


## 📦 The churn_model.pkl File
Once training completes, I serialize the entire preprocessing + model pipeline into churn_model.pkl.

This is a pickled Python object—in plain terms, it’s your entire preprocessing + model pipeline serialized (“saved”) to disk.


To reuse this model in another script or a live service:

```python
import joblib
pipeline = joblib.load("churn_model.pkl")
# `pipeline` now includes both feature transforms and the RandomForestClassifier

# Make predictions on new data:
new_data = ...  # pandas DataFrame with same columns
risk_scores = pipeline.predict_proba(new_data)[:, 1]
print("Churn probabilities:", risk_scores)
```

This way, you never have to retrain or rebuild encoders—just load and score.

## 🤝 Contributing
To contribute:

1. Fork this repository.

2. Create a feature branch:
    ```bash
    git checkout -b feature/YourFeature
    ```
3. Commit your changes:
    ```bash
    git commit -m "Add new feature"
    ```
4. Push to your fork:
    ```bash
    git push origin feature/YourFeature
    ```
5. Open a Pull Request describing your changes.

Please include unit tests for new functionality and update this README as needed.

## 📜 License
This project is distributed under the MIT License. See the LICENSE file for details.

## 📬 Contact
Website: https://david-okello.webflow.io/

LinkedIn: https://www.linkedin.com/in/david-okello-3599b51a0/

Email: okellodavid002@gmail.com 