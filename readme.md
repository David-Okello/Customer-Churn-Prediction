# Customer Churn Prediction Toolkit

> An end-to-end pipeline to simulate customer data, engineer features, and train a  Random Forest model for predicting customer churn.


## ğŸš€ Key Features

- **Synthetic Data Generation**  
  - `generate_customer_data.py` creates a realistic dataset of ~1,000 customers, including Recency-Frequency-Monetary (RFM) metrics, demographics, and support ticket counts.

- **Feature Engineering & Preprocessing**  
  - Automatic handling of missing values, scaling of numeric features, and encoding of categorical variables via Scikit-learnâ€™s `ColumnTransformer`.

- **Model Training & Tuning**  
  - `churnpred.py` implements a `Pipeline` that engineers features and fits a `RandomForestClassifier` with hyperparameter tuning via `GridSearchCV`.

- **Evaluation & Persistence**  
  - Outputs best ROC AUC score and optimal hyperparameters.  
  - Saves the final `RandomForest` model as `churn_model.pkl` for downstream inference.

- **Reproducibility**  
  - All randomness is controlled via fixed random seeds.  
  - Dependencies locked in `requirements.txt`.



## ğŸ“‚ Repository Structure
â”œâ”€â”€ customer_data.csv # Synthetic dataset (auto-regenerated by the script)

â”œâ”€â”€ generate_customer_data.py # Script to simulate and save customer data

â”œâ”€â”€ churnpred.py # Full pipeline: preprocess, feature engineer, train, evaluate

â”œâ”€â”€ churn_model.pkl # Serialized best Random Forest model

â”œâ”€â”€ requirements.txt # Project dependencies

â””â”€â”€ README.md # â† This file



## ğŸ› ï¸ Installation

1. **Clone the repository**  
   ```bash
   git clone https://github.com/David-Okello/Customer-Churn-Prediction.git
   cd customer-churn-prediction
    ```
2. Create & activate a virtual environment
    ```bash
    python -m venv .venv
    # Windows
    .\.venv\Scripts\Activate
    # macOS/Linux
    source .venv/bin/activate
    ```
3. Install dependencies
    ```bash
    pip install --upgrade pip
    pip install -r requirements.txt
    ```
## ğŸ’¡ Usage

1. Generate Synthetic Customer Data
    ```bash
    python generate_customer_data.py
    ```

    Produces customer_data.csv with features:

    - recency_days: Days since last purchase
    - frequency: Number of transactions
    - monetary_value: Total spend
    - region: Customer region (e.g., North America, EMEA)
    - tier: Service tier (e.g., Basic, Premium)
    - support_tickets: Number of tickets raised
    - churn: Binary target (0 = retained, 1 = churned)

2. Train & Evaluate the Churn Model
    ```bash
    python churnpred.py
    ```

    This triggers the full pipeline:

    1. Loads customer_data.csv.
    2. Preprocesses numeric & categorical features.
    3. Trains a RandomForestClassifier with hyperparameter tuning.
    4. Evaluates on a hold-out split.
    5. Prints metrics & parameters.
    6. Saves the final model to churn_model.pkl.

## ğŸ“Š Interpreting the Script Output (Nerding Out!ğŸ˜…)
When you run:
```cmd
(.venv) C:\â€¦\customer-churn-prediction> python churnpred.py
Best ROC AUC: 1.0
Best params: {'clf__max_depth': 5, 'clf__n_estimators': 100}
Sample risk scores: [0.07642917 0.08650294 0.05018108]
```

Hereâ€™s what each line means:

1. Best ROC AUC: 1.0

    - ROC AUC (Receiver Operating Characteristic Area Under the Curve) is a measure of classification quality that ranges from 0.5 (no better than flipping a coin) to 1.0 (perfect).
    - A value of 1.0 means it perfectly separated churners from non-churners on the test split (common with clean, synthetic data).
        - In real-world scenarios you rarely see a perfect 1.0, but here it just shows â€œthe pipeline worked and found a parameter set that perfectly classified the held-out examples.â€

2. Best params: {'clf__max_depth': 5, 'clf__n_estimators': 100}
    
    These are the hyperparameters the grid search settled on:

    - n_estimators=100: The â€œforestâ€ size i.e. how many decision trees the Random Forest builds. More trees can improve stability but cost more compute.
    - max_depth=5: 	How deep each tree is allowed to grow. A depth of 5 means each tree makes at most 5 â€œyes/noâ€ splits from root to leaf. Each tree can split at most 5 times, controlling complexity.

3. Sample risk scores: [0.0764, 0.0865, 0.0502]

    These are predicted probabilities of churn for the first three customers in the test set. Think of each as:

    > â€œMy model believes Customer #1 has a 7.64% chance of churning, Customer #2 about 8.65%, Customer #3 about 5.02%.â€
    - e.g. 0.0764 â†’ 7.64% chance of churning.

    Low numbers mean â€œlikely to stay,â€ higher numbers (close to 1.0) would mean â€œvery likely to churn. (not stay)â€ One can use these risk scores to prioritize who to call, send retention offers to, etc.


## ğŸ“¦ The churn_model.pkl File
Once training completes, I serialize the entire preprocessing + model pipeline into churn_model.pkl.

This is a pickled Python objectâ€”in plain terms, itâ€™s your entire preprocessing + model pipeline serialized (â€œsavedâ€) to disk.


To reuse this model in another script or a live service:

```python
import joblib
pipeline = joblib.load("churn_model.pkl")
# `pipeline` now includes both feature transforms and the RandomForestClassifier

# Make predictions on new data:
new_data = ...  # pandas DataFrame with same columns
risk_scores = pipeline.predict_proba(new_data)[:, 1]
print("Churn probabilities:", risk_scores)
```

This way, you never have to retrain or rebuild encodersâ€”just load and score.

## ğŸ¤ Contributing
To contribute:

1. Fork this repository.

2. Create a feature branch:
    ```bash
    git checkout -b feature/YourFeature
    ```
3. Commit your changes:
    ```bash
    git commit -m "Add new feature"
    ```
4. Push to your fork:
    ```bash
    git push origin feature/YourFeature
    ```
5. Open a Pull Request describing your changes.

Please include unit tests for new functionality and update this README as needed.

## ğŸ“œ License
This project is distributed under the MIT License. See the LICENSE file for details.

## ğŸ“¬ Contact
Website: https://david-okello.webflow.io/

LinkedIn: https://www.linkedin.com/in/david-okello-3599b51a0/

Email: okellodavid002@gmail.com 